Preprocessing data...
Aggregating data...
Aggregating observations...
Processing observations: 100%|████████████████████████████████| 40761/40761 [00:27<00:00, 1489.18it/s]
Merging data...
Merging steps: 100%|████████████████████████████████████████████████████| 5/5 [00:01<00:00,  4.48it/s]
Formatting final text...

Class distribution before balancing:
label
non-COVID    216676
COVID-19       6406
Name: count, dtype: int64

Class distribution after balancing:
label
non-COVID    216676
COVID-19     216676
Name: count, dtype: int64
Creating CSV from Arrow format: 100%|██████████████████████████████| 434/434 [00:01<00:00, 367.74ba/s]
Creating CSV from Arrow format: 100%|████████████████████████████████| 32/32 [00:00<00:00, 379.86ba/s]
Creating CSV from Arrow format: 100%|████████████████████████████████| 67/67 [00:00<00:00, 385.42ba/s]

Final dataset statistics:
Train size: 433352
Validation size: 31644
Test size: 66802

Data preparation complete. Dataset saved to: processed_data
Loading data...
Parsing text components...
Analyzing data and creating charts...
Analysis complete! Results saved to ./processed_data/charts
Generating train split: 433352 examples [00:00, 656841.10 examples/s]
Generating validation split: 31644 examples [00:00, 629068.07 examples/s]
Generating test split: 66802 examples [00:00, 687270.71 examples/s]
Map: 100%|██████████████████████████████████████████| 433352/433352 [00:04<00:00, 94837.07 examples/s]
Map: 100%|████████████████████████████████████████████| 31644/31644 [00:00<00:00, 95680.37 examples/s]
Map: 100%|████████████████████████████████████████████| 66802/66802 [00:00<00:00, 94420.65 examples/s]
Loading checkpoint shards: 100%|████████████████████████████████████████| 2/2 [00:01<00:00,  1.08it/s]
Map: 100%|███████████████████████████████████████████| 433352/433352 [02:19<00:00, 3112.88 examples/s]
Map: 100%|█████████████████████████████████████████████| 31644/31644 [00:10<00:00, 3162.71 examples/s]
Map: 100%|█████████████████████████████████████████████| 66802/66802 [00:21<00:00, 3171.54 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|                                                                         | 0/100 [00:00<?, ?it/s]The input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.float16.
{'loss': 2.4219, 'grad_norm': 1.0206555128097534, 'learning_rate': 8.099999831756577e-05, 'epoch': 0.0}
{'loss': 1.5895, 'grad_norm': 1.5355401039123535, 'learning_rate': 6.0999998822808266e-05, 'epoch': 0.0}
{'loss': 1.0267, 'grad_norm': 1.6558414697647095, 'learning_rate': 4.099999932805076e-05, 'epoch': 0.0}
{'loss': 0.8255, 'grad_norm': 2.201780080795288, 'learning_rate': 2.0999998014303856e-05, 'epoch': 0.0}
{'loss': 0.7719, 'grad_norm': 1.510035514831543, 'learning_rate': 9.999999974752427e-07, 'epoch': 0.0}
{'eval_loss': 0.9178204536437988, 'eval_runtime': 4195.4321, 'eval_samples_per_second': 7.542, 'eval_steps_per_second': 3.771, 'epoch': 0.0}                                                                
{'train_runtime': 4554.6586, 'train_samples_per_second': 0.351, 'train_steps_per_second': 0.022, 'train_loss': 1.3271068572998046, 'epoch': 0.0}                                                            
100%|█████████████████████████████████████████████████████████████| 100/100 [1:15:54<00:00, 45.55s/it]
100%|█████████████████████████████████████████████████████████| 33401/33401 [2:24:37<00:00,  3.85it/s]
Test set results: {'eval_loss': 0.8979175686836243, 'eval_runtime': 8677.9146, 'eval_samples_per_second': 7.698, 'eval_steps_per_second': 3.849, 'epoch': 0.003692148645904484}
Loading checkpoint shards: 100%|████████████████████████████████████████| 2/2 [00:01<00:00,  1.23it/s]
Device set to use cuda:0
/home/mchieberly/miniconda3/envs/llmtutor/lib/python3.10/site-packages/gradio/chat_interface.py:338: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.
  self.chatbot = Chatbot(
* Running on local URL:  http://127.0.0.1:7860

To create a public link, set `share=True` in `launch()`.
